{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#import library\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "F5CUNISqGnN6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add API key\n",
        "client = OpenAI(api_key=\"api_key\")"
      ],
      "metadata": {
        "id": "e74A_bC4K-IN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structured Output"
      ],
      "metadata": {
        "id": "KLnHUfQlEwXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### List"
      ],
      "metadata": {
        "id": "fv7ycL-PFCny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tu5xEJ3DEGMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be778d62-f7cc-4c6d-8c21-e2674f93c430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Key Industries AI is Transforming:\n",
            "  - Healthcare\n",
            "  - Finance\n",
            "  - Education\n",
            "\n",
            "- Impact of AI:\n",
            "  - Improving efficiency\n",
            "  - Enhancing decision making\n"
          ]
        }
      ],
      "source": [
        "text = \"Artificial Intelligence is transforming industries like healthcare, finance, and education by improving efficiency and decision making.\"\n",
        "prompt = f\"\"\"Format the response in a list:\n",
        "- Summarize the key industries AI is transforming.\n",
        "- Highlight its impact.\n",
        "\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tables"
      ],
      "metadata": {
        "id": "N3VlKLQ-nWd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"YTesla is an electric vechicle company. Its stock price has increased by 20% in the las year. Apple is a technology company known for its iphones.\\\n",
        "Its stock price has increased by 15% in the last year. Amazon is an e-commerce and cloud computing giant. Its stock price has increased by 10% in the last year.\"\n",
        "prompt = f\"\"\"Convert the following information into a table format with columns for company, industry, and stock performance:\n",
        "\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "u3QbwsX7nhq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e103eb30-acb9-477b-a4e7-9e2655b30eb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the information in a table format:\n",
            "\n",
            "| Company | Industry                        | Stock Performance |\n",
            "|---------|---------------------------------|-------------------|\n",
            "| Tesla   | Electric Vehicle                | Increased by 20%  |\n",
            "| Apple   | Technology                      | Increased by 15%  |\n",
            "| Amazon  | E-commerce and Cloud Computing  | Increased by 10%  |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### JSON\n"
      ],
      "metadata": {
        "id": "qtUPEbrSoXuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"John is a Data Scientist with expertise in python and machine learning.\"\n",
        "prompt = f\"\"\"Extract the key details from text and return output in JSON format.\n",
        "\n",
        "{{\n",
        "  \"name\": \"\",\n",
        "  \"role\": \"\",\n",
        "  \"skills\": []\n",
        "}}\n",
        "\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "oYjerOzTpZRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03efdcfc-1119-4a69-a0de-7d82e0dfeee8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"name\": \"John\",\n",
            "  \"role\": \"Data Scientist\",\n",
            "  \"skills\": [\"python\", \"machine learning\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Structured Paragraph"
      ],
      "metadata": {
        "id": "Jtmc65FRqg7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write a structured paragrapgh with clear headings and sub-headings about the impact of a balanced diet on physical and mental health.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "6jQad8lOq9TD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b8befb-5520-43ec-ffc6-793b71c6e389"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# The Impact of a Balanced Diet on Physical and Mental Health\n",
            "\n",
            "## Introduction\n",
            "A balanced diet, comprising a variety of nutrients in appropriate proportions, is essential for maintaining overall health. It plays a crucial role in supporting both physical and mental well-being, influencing everything from energy levels to mood stability.\n",
            "\n",
            "## Physical Health Benefits\n",
            "\n",
            "### Energy and Vitality\n",
            "A balanced diet provides the necessary nutrients and energy required for daily activities. Carbohydrates, proteins, and fats serve as primary energy sources, while vitamins and minerals support metabolic processes, ensuring sustained energy levels throughout the day.\n",
            "\n",
            "### Disease Prevention\n",
            "Consuming a diet rich in fruits, vegetables, whole grains, and lean proteins can reduce the risk of chronic diseases such as obesity, heart disease, diabetes, and certain cancers. Nutrients like antioxidants, fiber, and healthy fats contribute to a robust immune system and improved cardiovascular health.\n",
            "\n",
            "### Weight Management\n",
            "A balanced diet helps in maintaining a healthy weight by providing the right amount of calories and nutrients. It prevents overeating and promotes a healthy metabolism, reducing the risk of weight-related health issues.\n",
            "\n",
            "## Mental Health Benefits\n",
            "\n",
            "### Mood Regulation\n",
            "Nutrients such as omega-3 fatty acids, B vitamins, and amino acids are vital for brain health and neurotransmitter function. A balanced diet can help stabilize mood swings and reduce symptoms of depression and anxiety.\n",
            "\n",
            "### Cognitive Function\n",
            "Proper nutrition supports cognitive functions like memory, concentration, and problem-solving. Foods rich in antioxidants and healthy fats, such as berries and nuts, protect brain cells and enhance mental clarity.\n",
            "\n",
            "### Stress Reduction\n",
            "A diet that includes magnesium, zinc, and vitamin C can help manage stress levels. These nutrients play a role in regulating the body's stress response, promoting relaxation and mental resilience.\n",
            "\n",
            "## Conclusion\n",
            "In summary, a balanced diet is fundamental to achieving optimal physical and mental health. By providing essential nutrients, it supports energy levels, disease prevention, weight management, mood regulation, cognitive function, and stress reduction. Prioritizing a balanced diet can lead to a healthier, more fulfilling life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom Output"
      ],
      "metadata": {
        "id": "TaWMnSlIruvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"In a distant kingdom, a brave knight named Arthur set out on a quest to find a legendary sword of light. Through treacherous mountains\\\n",
        "and dark forest he faced numerous challenges but remained determined to fulfill his destiny.\"\n",
        "\n",
        "instruction = \"You will be provided with a text delimited triple backticks. Generate a short summary for it\"\n",
        "\n",
        "output_format = \"\"\"Use the following format for the output:\n",
        "Text: <text to be summarized>\n",
        "Summary: <the generated summary>\"\"\"\n",
        "\n",
        "prompt = instruction + output_format + f\"```{text}```\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "a_1TAiaDrx4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495fe096-d620-46d3-9c94-06215d84fcae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: In a distant kingdom, a brave knight named Arthur set out on a quest to find a legendary sword of light. Through treacherous mountains and dark forest he faced numerous challenges but remained determined to fulfill his destiny.\n",
            "\n",
            "Summary: Arthur, a courageous knight, embarks on a perilous journey through mountains and forests to find a legendary sword of light, overcoming various challenges to fulfill his destiny.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conditional Prompt"
      ],
      "metadata": {
        "id": "BuX7wmh24Sp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"In a distant kingdom, a brave knight named Arthur set out on a quest to find a legendary sword of light. Through treacherous mountains\\\n",
        "and dark forest he faced numerous challenges but remained determined to fulfill his destiny.\"\n",
        "\n",
        "prompt = f\"\"\"You will be provided with a text delimited triple backticks.\n",
        "- If the text is short (around 20 word or fewer), generate a suitable **Title**.\n",
        "- If the text is longer 20 words, generate a concise **Summary**.\n",
        "\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "TwFDfL6l4R_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ce9d8b8-d8f6-4ba1-c832-72aad11796a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Title:** The Quest for the Legendary Sword of Light\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Prompt Engineering\n",
        "\n",
        "Advanced prompt engineering techniques enhance the performance of AI models by providing structured input.\n",
        "\n",
        "We will cover six key techniques:\n",
        "- Zero-shot prompting\n",
        "- One-shot prompting\n",
        "- Few-shot prompting\n",
        "- Multi-step prompting\n",
        "- Chain-of-thought prompting\n",
        "- Self-consistency prompting"
      ],
      "metadata": {
        "id": "ezZQaO-Y5ooj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Zero-shot\n",
        "\n",
        "Zero-shot prompting involves providing the model with a direct question or task without any prior examples."
      ],
      "metadata": {
        "id": "DhnBc0Mv56DG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Translate the following Englisg sentence in French: 'The weather is nice today.'\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "LfMZl-L65zqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7f5912-5bfb-4e6c-cc3b-d8837b8007f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The French translation of 'The weather is nice today.' is 'Il fait beau aujourd'hui.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-shot\n",
        "\n",
        "One-shot prompting provides the model with a single example before asking it to generate a response.\n"
      ],
      "metadata": {
        "id": "qCrVAJMI6nb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Detect the languages of the following sentences:\n",
        "text: \"Good morning\" -> language: \"English\"\n",
        "text: \"A plus tard\" -> language: \"French\"\n",
        "Now detect the language of the following sentence:\n",
        "text: \"Gracias!\" ->\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "LjAVP7C96mvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53d229e-48fd-49e9-ef50-2e3e0fd5239c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language: \"Spanish\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-shot\n",
        "\n",
        "Few-shot prompting gives the model multiple examples to learn the task before requesting a response."
      ],
      "metadata": {
        "id": "xRf0E6Pk7c1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Determine the sentiment of the following sentences:\n",
        "text: \"I love this product! it works perfectly.\" -> sentiment: Positive\n",
        "text: \"The service was terrible. I am very disappointed.\" -> sentiment: Negative\n",
        "text: \"The food was okay, nothing special.\" -> sentiment: Neutral\n",
        "Now analyze this sentence:\n",
        "text: \"The movie was amazing! I enjoyed every moment of it\".\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "ZnQB1CIB7r3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92543a5f-9d12-4a73-ed40-2521ff1d6023"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-step Prompting\n",
        "\n",
        "Multi-step prompting involves breaking down a complex query into smaller, manageable steps to improve model accuracy."
      ],
      "metadata": {
        "id": "8UdcImz58yH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Marie Currie discovered Radium in 1898\"\n",
        "\n",
        "prompt = f\"\"\"You will be provided with a text delimited by triple backticks.\n",
        "step 1: Identify the key entities in the sentence.\n",
        "step 2: Classify each entity as person, event, or object.\n",
        "\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "jKPOcXQY86St",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1657c4c8-bef4-4795-df0d-1d86bf020a08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Identify the key entities in the sentence.\n",
            "- Marie Currie\n",
            "- Radium\n",
            "- 1898\n",
            "\n",
            "Step 2: Classify each entity as person, event, or object.\n",
            "- Marie Currie: Person\n",
            "- Radium: Object\n",
            "- 1898: Event (as it refers to the year of the discovery)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chain-of-thought prompting\n",
        "\n",
        "Chain-of-thought prompting encourages the model to break down reasoning into logical steps before answering."
      ],
      "metadata": {
        "id": "tem3AOoX95le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"John has three apples, he buys five more and gives two away. How many apples does he have? Think step by step.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "j76l4phO-B4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcbf1132-d64f-4468-d93d-58823f8c49c9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break it down step by step:\n",
            "\n",
            "1. John starts with three apples.\n",
            "2. He buys five more apples. So, we add the five apples to the three he already has:  \n",
            "   \\(3 + 5 = 8\\) apples.\n",
            "3. John then gives away two apples. So, we subtract the two apples he gives away from the eight apples he has:  \n",
            "   \\(8 - 2 = 6\\) apples.\n",
            "\n",
            "Therefore, John has 6 apples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Self-consistency prompting\n",
        "\n",
        "Self-consistency prompting generates multiple responses and selects the most consistent answer to improve accuracy.\n"
      ],
      "metadata": {
        "id": "C2UOXnLn-fuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"Imagine three completely independent experts who reason differently are answering this question. Show their reasoning step by step.\n",
        "The final answer is obtained by majority vote. The question is:\"\"\"\n",
        "\n",
        "question = \"\"\"A book store has 20 books on a shelf. A customer buys 5 books. Then, the store restocks with double of the number of books bought.\n",
        "After that, another customer buys 8 books. How many books are left on the shelf?\"\"\"\n",
        "\n",
        "prompt = instruction + question\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "5mpSEidT-iu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7908ea-423c-4e6f-f3b1-6374e533b6c0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve this problem, let's consider the reasoning of three independent experts, each with a different approach.\n",
            "\n",
            "**Expert 1: The Sequential Thinker**\n",
            "\n",
            "1. **Initial Count**: The bookstore starts with 20 books on the shelf.\n",
            "2. **First Transaction**: A customer buys 5 books.\n",
            "   - Books left = 20 - 5 = 15 books.\n",
            "3. **Restocking**: The store restocks with double the number of books bought (5 books were bought, so 10 books are restocked).\n",
            "   - Books after restocking = 15 + 10 = 25 books.\n",
            "4. **Second Transaction**: Another customer buys 8 books.\n",
            "   - Books left = 25 - 8 = 17 books.\n",
            "\n",
            "**Expert 2: The Algebraic Thinker**\n",
            "\n",
            "1. **Define Variables**: Let \\( x \\) be the initial number of books, \\( y \\) be the number of books bought by the first customer, and \\( z \\) be the number of books bought by the second customer.\n",
            "   - \\( x = 20 \\), \\( y = 5 \\), \\( z = 8 \\).\n",
            "2. **First Transaction**: Calculate the remaining books after the first purchase.\n",
            "   - Remaining books = \\( x - y = 20 - 5 = 15 \\).\n",
            "3. **Restocking**: The store restocks with \\( 2y \\) books.\n",
            "   - Restocked books = \\( 2 \\times 5 = 10 \\).\n",
            "   - Total books after restocking = \\( 15 + 10 = 25 \\).\n",
            "4. **Second Transaction**: Calculate the remaining books after the second purchase.\n",
            "   - Remaining books = \\( 25 - z = 25 - 8 = 17 \\).\n",
            "\n",
            "**Expert 3: The Visual Thinker**\n",
            "\n",
            "1. **Visualize Initial Shelf**: Picture a shelf with 20 books.\n",
            "2. **First Customer**: Visualize removing 5 books from the shelf.\n",
            "   - Books left visually = 15 books.\n",
            "3. **Restocking**: Imagine adding 10 more books to the shelf.\n",
            "   - Books after restocking visually = 25 books.\n",
            "4. **Second Customer**: Visualize removing 8 books from the shelf.\n",
            "   - Books left visually = 17 books.\n",
            "\n",
            "**Majority Vote Conclusion**\n",
            "\n",
            "All three experts, despite their different reasoning approaches, conclude that there are 17 books left on the shelf. Therefore, the final answer by majority vote is:\n",
            "\n",
            "**17 books**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practical Applications of Prompt Engineering\n",
        "\n",
        "We will be considering six key application areas:\n",
        "\n",
        "- Text summarization\n",
        "- Text transformation\n",
        "- Text analysis\n",
        "- Code generation\n",
        "- Chatbot development\n",
        "- Role playing prompt for chatbot"
      ],
      "metadata": {
        "id": "amjROpJ0ALp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text Summarization\n",
        "\n",
        "- Scenario: Automated News Summarization\n",
        "- Use Case: A media company wants to provide quick news digests for users.  \n",
        "- Real-World Impact: Helps busy people stay updated without reading lengthy articles."
      ],
      "metadata": {
        "id": "5Ei5UOWJAgeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Tech giant InnovateX have announced a breakthrough in quantum computing, unveiling a new processor that is 10 times faster than\n",
        "previous models. The company claims this advancement will revolutionize industries such as cytography, pharmaceuticals, and artificial intelligence.\n",
        "Experts believe this could lead to significant improvements in data encryption and drug discovery. The new processor is expected to be available for\n",
        "commercial use by 2026.\"\"\"\n",
        "\n",
        "prompt = f\"\"\"Summarize the news article delimited by triple backticks in three bullets points, keeping key details intact.\n",
        "\n",
        "```{text}```\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "I2peTAxYAfDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8797091d-8535-4087-d166-2ae3c9760878"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- InnovateX has announced a significant breakthrough in quantum computing with a new processor that is 10 times faster than previous models.\n",
            "- This advancement is expected to revolutionize industries including cryptography, pharmaceuticals, and artificial intelligence, potentially leading to major improvements in data encryption and drug discovery.\n",
            "- The new processor is anticipated to be available for commercial use by 2026.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text Transformation\n",
        "\n",
        "- Scenario: Improving Job Application Emails\n",
        "- Use Case: A job seeker wants to make their email to a hiring manager more professional.\n",
        "- Real-World Impact: Helps job seekers make a strong first impression."
      ],
      "metadata": {
        "id": "CfUEZPHdCyen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Subject: Applying for Data Analyst Job\n",
        "Hey, I saw your job post for a data analyst and I am really interested. I've worked with data before and think I would be a great fit.\n",
        "My resume is attached. Let me know if you need anything else. Thanks!\n",
        "\"\"\"\n",
        "prompt = f\"\"\" Rewrite the email delimited by triple backticks in a professional tone.\n",
        "\n",
        "```{text}```\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "lSoc95G0C7pM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c461d1b-58d1-48a3-9484-b2a258a74dc5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Application for Data Analyst Position\n",
            "\n",
            "Dear [Recipient's Name],\n",
            "\n",
            "I hope this message finds you well. I am writing to express my interest in the Data Analyst position advertised. With my experience in data analysis, I am confident in my ability to contribute effectively to your team.\n",
            "\n",
            "Please find my resume attached for your review. Should you require any additional information, feel free to contact me.\n",
            "\n",
            "Thank you for considering my application. I look forward to the opportunity to discuss how I can contribute to your organization.\n",
            "\n",
            "Warm regards,\n",
            "\n",
            "[Your Name]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text Analysis\n",
        "\n",
        "- Scenario: Sentiment Analysis for Product Reviews\n",
        "- Use Case: An e-commerce platform wants to categorize customer reviews as Positive, Neutral, or Negative.\n",
        "- Real-World Impact: Helps businesses improve products based on customer feedback."
      ],
      "metadata": {
        "id": "V8P2fW7NEi69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"I ordered this smart phone last week, and I'm really impressed. The battery lasts all day, the camera quality is amazing and it runs\n",
        "super smoothly. Definitely worth the price!\"\"\"\n",
        "\n",
        "prompt =f\"\"\"Classify the sentiment of the review delimited by triple backticks as Positive, Neutral, or Negative.\n",
        "\n",
        "```{text}```\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "g6VmDde9ErB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af166d5d-b20a-47bc-ccbb-c3b7fc331dc4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code Generation\n",
        "\n",
        "- Scenario: AI-Assisted Code Writing for Developers\n",
        "- Use Case: A junior developer needs a Python function to sort a list of dictionaries.\n",
        "- Real worls Impact: Speeds up development and enhances productivity."
      ],
      "metadata": {
        "id": "m0yl-l-RFinD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write a Python function that sort a list of dictionaries by a specific key.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "q_58nfWMFts3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f208b7-58ee-4977-e5ca-39eb3761c76e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! You can sort a list of dictionaries by a specific key using Python's built-in `sorted()` function. Here's a function that does exactly that:\n",
            "\n",
            "```python\n",
            "def sort_dicts_by_key(dicts_list, key):\n",
            "    \"\"\"\n",
            "    Sorts a list of dictionaries by a specified key.\n",
            "\n",
            "    Parameters:\n",
            "    dicts_list (list): A list of dictionaries to be sorted.\n",
            "    key (str): The key by which to sort the dictionaries.\n",
            "\n",
            "    Returns:\n",
            "    list: A new list of dictionaries sorted by the specified key.\n",
            "    \"\"\"\n",
            "    try:\n",
            "        return sorted(dicts_list, key=lambda x: x[key])\n",
            "    except KeyError:\n",
            "        print(f\"KeyError: One or more dictionaries do not contain the key '{key}'.\")\n",
            "        return dicts_list\n",
            "    except TypeError:\n",
            "        print(\"TypeError: The provided list is not a list of dictionaries or the key values are not comparable.\")\n",
            "        return dicts_list\n",
            "\n",
            "# Example usage:\n",
            "dicts = [\n",
            "    {'name': 'Alice', 'age': 30},\n",
            "    {'name': 'Bob', 'age': 25},\n",
            "    {'name': 'Charlie', 'age': 35}\n",
            "]\n",
            "\n",
            "sorted_dicts = sort_dicts_by_key(dicts, 'age')\n",
            "print(sorted_dicts)\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- The function `sort_dicts_by_key` takes two parameters: `dicts_list`, which is the list of dictionaries you want to sort, and `key`, which is the key by which you want to sort the dictionaries.\n",
            "- The `sorted()` function is used to sort the list. It takes a `key` argument, which is a function that extracts the key to sort by from each dictionary. Here, a lambda function `lambda x: x[key]` is used for this purpose.\n",
            "- The function handles potential `KeyError` exceptions if the specified key is not present in one or more dictionaries, and `TypeError` if the list is not a list of dictionaries or the key values are not comparable.\n",
            "- The function returns a new list of dictionaries sorted by the specified key. If an error occurs, it returns the original list and prints an error message.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chatbot Development\n",
        "\n",
        "- Scenario: Customer Support AI Assistant\n",
        "- Use Case: A chatbot for a bank to assist users with transaction issues.\n",
        "- Real-World Impact: Improves customer satisfaction by resolving queries instantly."
      ],
      "metadata": {
        "id": "-ZeioeZSGNfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"You are an AI Assistant for a bank's customer support. Your role is to assist user with transaction-related issues in a\n",
        "polite, professional and helpful manner. If a user asks about failed transaction, provide troubleshooting steps such as checking their\n",
        "account balance, verifying transaction details, and contacting support if neccessary. Keep your responses clear and concise while still maintaining\n",
        "a friendly tone.\"\"\"\n",
        "\n",
        "user_prompt = \"Hi, I tried making a payment but it failed. What should I do?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "7UiyXFMFGdih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0e9df6-0b4d-4360-d47b-526420f1b057"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry to hear that your payment didn't go through. Let's try a few steps to resolve this issue:\n",
            "\n",
            "1. **Check Your Account Balance**: Ensure that you have sufficient funds in your account to cover the transaction.\n",
            "\n",
            "2. **Verify Transaction Details**: Double-check the payment details, such as the recipient's account number, the amount, and any reference numbers, to make sure everything is correct.\n",
            "\n",
            "3. **Review Transaction Limits**: Some accounts have daily or transaction limits. Make sure your attempted payment doesn't exceed these limits.\n",
            "\n",
            "4. **Check for Alerts**: Look for any alerts or notifications from your bank that might explain why the transaction failed.\n",
            "\n",
            "5. **Try Again**: If everything seems correct, try processing the payment again.\n",
            "\n",
            "6. **Contact Support**: If the issue persists, please contact our customer support team for further assistance. They can provide more detailed help and investigate any potential issues with your account.\n",
            "\n",
            "If you need any more help, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Role-playing Prompt for Chatbot\n",
        "\n",
        "- Scenario: AI-Powered Interview Coach\n",
        "- Use Case: Job seekers use an AI to practice interview questions and receive feedback.\n",
        "- Helps candidates prepare effectively for real interview."
      ],
      "metadata": {
        "id": "6rE-ApJIJSEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"Act as an experienced hiring manager. Ask me one interview questions one by one. After I respond, provide constructive feedback\n",
        "on my answer, including strengths and areas for improvement. If my response is incomplete, guide me towards a better answer. \"\"\"\n",
        "\n",
        "user_prompt = \"I am prepearing for a Data Scientist interview. Can you ask me five questions and evaluate my responses?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "v8OyYvAhJcjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52ceb31-80b5-4193-a79a-e850191c547c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Let's start with the first question:\n",
            "\n",
            "**Question 1:** Can you describe a data science project you've worked on from start to finish? What was the problem you were trying to solve, and what was the outcome?\n"
          ]
        }
      ]
    }
  ]
}