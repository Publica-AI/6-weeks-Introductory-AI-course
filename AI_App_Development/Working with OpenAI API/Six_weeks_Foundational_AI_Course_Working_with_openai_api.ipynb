{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Required Library"
      ],
      "metadata": {
        "id": "_wviJvl2TLDm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JyX9wZPJmHl"
      },
      "outputs": [],
      "source": [
        "#!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "KZqmWrGEKLCk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add your API key"
      ],
      "metadata": {
        "id": "xhSXNPEqMDIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key = \"api_key\")"
      ],
      "metadata": {
        "id": "dll4A7WuMFQH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making request to openAIâ€™s text and chat endpoint"
      ],
      "metadata": {
        "id": "q39pkjDWLVyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"What is Generative AI\"}])"
      ],
      "metadata": {
        "id": "Bln4Wp-_Tfxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "CdD4XwZ3LoPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b8d738-9bad-4db7-c071-eb259cfb348f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-BAy1F2wxgheTXctXijkpdi4dH9Ijj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Generative AI refers to a subset of artificial intelligence techniques that focus on creating new content, data, or artifacts that mimic human-like creativity. Unlike traditional AI systems, which often analyze and make predictions based on existing data, generative AI uses models to generate new outputs, such as text, images, music, or even video.\\n\\nKey characteristics of generative AI include:\\n\\n1. **Data Generation**: It can produce original content based on patterns learned from training data. For example, a generative AI model trained on novels can generate coherent and contextually relevant text.\\n\\n2. **Deep Learning Techniques**: Many generative AI models utilize deep learning architectures, such as Generative Adversarial Networks (GANs) or Variational Autoencoders (VAEs), to learn the distribution of data and generate new instances from that distribution.\\n\\n3. **Interactivity**: Some generative AI systems can respond to user prompts or input, creating tailored content on demand. For example, AI image generators can create images based on textual descriptions provided by users.\\n\\n4. **Wide Applications**: Generative AI finds applications in numerous fields, including design (creating graphics or product designs), entertainment (writing scripts or generating music), marketing (creating personalized content), and research (synthesizing new chemical compounds or drug formulations).\\n\\n5. **Ethical Considerations**: The rise of generative AI has led to discussions about copyright, the potential for misinformation, and the ethical implications of AI-generated content.\\n\\nOverall, generative AI represents a significant step in the evolution of artificial intelligence, enabling machines to create new and innovative outputs that can have practical and artistic value.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1741953693, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_06737a9306', usage=CompletionUsage(completion_tokens=333, prompt_tokens=12, total_tokens=345, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "GK6KrXr7LkT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46430ce2-a1d4-4d34-9874-65c42393dc34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative AI refers to a subset of artificial intelligence techniques that focus on creating new content, data, or artifacts that mimic human-like creativity. Unlike traditional AI systems, which often analyze and make predictions based on existing data, generative AI uses models to generate new outputs, such as text, images, music, or even video.\n",
            "\n",
            "Key characteristics of generative AI include:\n",
            "\n",
            "1. **Data Generation**: It can produce original content based on patterns learned from training data. For example, a generative AI model trained on novels can generate coherent and contextually relevant text.\n",
            "\n",
            "2. **Deep Learning Techniques**: Many generative AI models utilize deep learning architectures, such as Generative Adversarial Networks (GANs) or Variational Autoencoders (VAEs), to learn the distribution of data and generate new instances from that distribution.\n",
            "\n",
            "3. **Interactivity**: Some generative AI systems can respond to user prompts or input, creating tailored content on demand. For example, AI image generators can create images based on textual descriptions provided by users.\n",
            "\n",
            "4. **Wide Applications**: Generative AI finds applications in numerous fields, including design (creating graphics or product designs), entertainment (writing scripts or generating music), marketing (creating personalized content), and research (synthesizing new chemical compounds or drug formulations).\n",
            "\n",
            "5. **Ethical Considerations**: The rise of generative AI has led to discussions about copyright, the potential for misinformation, and the ethical implications of AI-generated content.\n",
            "\n",
            "Overall, generative AI represents a significant step in the evolution of artificial intelligence, enabling machines to create new and innovative outputs that can have practical and artistic value.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Controlling randomness and response length"
      ],
      "metadata": {
        "id": "za_ZFdzoM6X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\":\"Write a poem on the rhythm of the ocean waves\"}],\n",
        "    temperature = 1.5,\n",
        "    max_tokens = 30)\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "AzT9eP2PLteh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a908d1f-bc14-44a9-a844-b9334a245bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In whispers low and gentle sighs,  \n",
            "The ocean calls from afar,  \n",
            "Where silver foams in wild embrace  \n",
            "And dances light 'neath the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Task"
      ],
      "metadata": {
        "id": "nNzdv6uCNG4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"Classify the following food items into classes: Rice, Meat, Cheese, Vegetables, Pasta, Eggs.\"}],\n",
        "    max_tokens = 30\n",
        "    )\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "HRmccpNQNI5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0cbd063-d016-4563-9f98-80b869868b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the classifications for the food items you provided:\n",
            "\n",
            "1. **Grains/Starches:**\n",
            "   - Rice\n",
            "   - Pasta\n",
            "\n",
            "2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Classification"
      ],
      "metadata": {
        "id": "VdfOVcrxOPXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Classify sentiments in the following statements:\n",
        "1. You did a great a job today!\n",
        "2. The sun is shining beautifully.\n",
        "3. I am feeling really tired and frustrated.\n",
        "4. I love spending time with my family.\n",
        "5. The food tasted awful.\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt}],\n",
        "    max_tokens = 50\n",
        "    )\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "9mPfmaUGOO_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b2b7b9-51d8-43ae-84ef-05962266a65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the sentiments classified for each statement:\n",
            "\n",
            "1. **Positive** - \"You did a great job today!\"\n",
            "2. **Positive** - \"The sun is shining beautifully.\"\n",
            "3. **Negative** - \"I am feeling really tired and frustrated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Moderation"
      ],
      "metadata": {
        "id": "VJ8e9Cr5PyTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.moderations.create(\n",
        "    model = \"text-moderation-latest\",\n",
        "    input = \"Let's meet up and I will send you some illegal stuff.\")\n",
        "\n",
        "print(response.results[0].category_scores)"
      ],
      "metadata": {
        "id": "gaFZK3_WP2yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85abaef6-9d00-4617-da32-d41fc2cf4e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CategoryScores(harassment=0.0008256346918642521, harassment_threatening=0.000993490219116211, hate=1.8259153875987977e-05, hate_threatening=1.2425508657543105e-06, illicit=None, illicit_violent=None, self_harm=4.546794571069768e-06, self_harm_instructions=9.162299363651982e-08, self_harm_intent=1.4249826563172974e-06, sexual=0.00011462330439826474, sexual_minors=2.3936334400787018e-05, violence=0.004845377057790756, violence_graphic=3.801782213486149e-06, self-harm=4.546794571069768e-06, sexual/minors=2.3936334400787018e-05, hate/threatening=1.2425508657543105e-06, violence/graphic=3.801782213486149e-06, self-harm/intent=1.4249826563172974e-06, self-harm/instructions=9.162299363651982e-08, harassment/threatening=0.000993490219116211)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speech Transcription"
      ],
      "metadata": {
        "id": "bYKR9_f2RELH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = open(\"/content/english_audio.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "    model = \"whisper-1\",\n",
        "    file = audio_file\n",
        ")\n",
        "\n",
        "print(transcript.text)"
      ],
      "metadata": {
        "id": "sEYmkQPjRI61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65c8d0d-0110-421e-8076-0b231ae1c049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcriber's Name Reviewer's Name Timing & Transcription by Rev.com Wow, what an audience. But if I'm being honest, I don't care what you think of my talk. I don't. I care what the Internet thinks of my talk. Because they're the ones who get it seen and get it shared. And I think that's where most people get it wrong. They're talking to you, here. Instead of talking to you, random person scrolling Facebook. Thanks for the click. You see, back in 2009, we all had these weird little things called attention spans. Yeah, they're gone. They're gone. We killed them. They're dead. I'm trying to think of the last time I watched an 18-minute TED talk. It's been years. Literally years. So if you're giving a TED talk, keep it quick. I've got two in mind in under a minute. I'm at 44 seconds right now. That means we've got time for one final joke. Why are balloons so expensive? Inflation. Thank you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speech Translation"
      ],
      "metadata": {
        "id": "49OZIOvURm76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = open(\"/content/french_audio.mp3\", \"rb\")\n",
        "translation = client.audio.translations.create(\n",
        "    model = \"whisper-1\",\n",
        "    file = audio_file\n",
        ")\n",
        "\n",
        "print(translation.text)"
      ],
      "metadata": {
        "id": "hImV0Nh_SDQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7aa93d6-3f62-4eb5-99c1-ea53fd665c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Music Car Honk Music Music Once upon a time, an old lady wanted to cross the road. But she was weak. Therefore, she asked for help. She waited a long time. She waited alone. She saw a large number of schoolchildren. They laughed and talked. They went home. They were happy. They looked at the old woman. But they didn't help her. But a boy went to see the old woman. He said to her, Mother, do you want to cross the road? Don't worry. I'll help you. I'll take you to the other side. The boy helped the old woman. He made her cross the road. He did a good deed. He was happy. He said, I helped someone's mother. So, someone will help my mother in her old age. The old woman said in her prayer, Dear God, be kind to this good boy. Music\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding additional context about transript"
      ],
      "metadata": {
        "id": "2zZ0ezA9S3UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file = open(\"/content/french_audio.mp3\", \"rb\")\n",
        "prompt = \"This is a short story\"\n",
        "translation = client.audio.translations.create(\n",
        "    model = \"whisper-1\",\n",
        "    file = audio_file,\n",
        "    prompt = prompt\n",
        ")\n",
        "\n",
        "print(translation.text)"
      ],
      "metadata": {
        "id": "CZolvVHYSedS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a032f4-7531-41c3-fe12-6f909ea401ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intro Honk honk Music Once upon a time, there was an old lady who wanted to cross the road, but she was weak, so she asked for help, she waited a long time, she waited alone, she saw a large number of schoolchildren, they laughed and talked. They went home, they were happy, they looked at the old woman, but they did not help her. But a boy went to see the old woman, he said to him. Mother, do you want to cross the road? Do not worry, I will help you, I will take you to the other side. The boy helped the old woman, he made her cross the road, he did a good deed, he was happy, he said. I helped someone's mother, so someone will help my mother in her old age. The old woman said in her prayer. Dear God, be kind to this good boy. Music\n"
          ]
        }
      ]
    }
  ]
}