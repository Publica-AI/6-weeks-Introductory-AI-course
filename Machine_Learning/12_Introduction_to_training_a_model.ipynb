{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfvpDs6eWj9xxvgLik0XfW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Understanding the Machine Learning Pipeline**"],"metadata":{"id":"2vWzhjr7ysWG"}},{"cell_type":"markdown","source":["An ML pipeline is a structured workflow that automates the process of building, training, evaluating, and deploying machine learning models. It ensures that data flows smoothly from raw input to a deployed model.\n","\n","But I am not explaining it in terms of automation, we will cover that when we get to MLOps. Here we will just be focusing on the flow only."],"metadata":{"id":"0Wo4GGYTzT7O"}},{"cell_type":"markdown","source":["**The Key Stages of ML Pipeline**"],"metadata":{"id":"-8BZn1pHz568"}},{"cell_type":"markdown","source":["**1. Data Collection and Ingestion**"],"metadata":{"id":"tODCqhbp0CwM"}},{"cell_type":"markdown","source":["The pipleine begins with data collection from various sources depending on the data need of your business or organization.\n","For reiteration you can get dataset from APIs, Webscaping, Databases, Devices, Logs, streaming data etc.."],"metadata":{"id":"N3C4fcEU1GNN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0LCTdsvoyk9a"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["**2. Data Preprocessing & Cleaning**"],"metadata":{"id":"nbEzphcX0KSs"}},{"cell_type":"markdown","source":["Remember that high quality data improves model performance. we have treated both data cleaning and data preprocessing in details."],"metadata":{"id":"LbH6RD2z1yBT"}},{"cell_type":"code","source":[],"metadata":{"id":"pMde6V9V0JT8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3. Feature Engineering & Transformation**"],"metadata":{"id":"LQKFKVSd0RBm"}},{"cell_type":"markdown","source":["Most times, data cleaning, preprocessing and engineering could intertwine but there are major differences. But at the end of the day, the 3 strateiges gears towards one goal, that is making a quality data ready for our model."],"metadata":{"id":"n1_VRATV1xfU"}},{"cell_type":"code","source":[],"metadata":{"id":"WUnMX_NZ0JvE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**4. Splitting Data**"],"metadata":{"id":"-KvuosuM0eIk"}},{"cell_type":"markdown","source":["To evaluate our model fairly, we have to split it into train and test sets. The train data should be considerably more, at least 65 to 80 percent of the data. And the rest of the data (test set) can be reserved for model evaluation.\n","\n","**K-Fold Cross-Validation**: This also comes in handy. Instead of a single train-test split,this splits the data into K parts(or folds). The algorithm  is trained and tested K times, using different fold as the test set each time.  This will help to prevent our algorthm fromlearning too much from one specific set. It beomes very useful when we have limited data, so it just help us to leverage on every data point for the training process."],"metadata":{"id":"rL5VaRv12uU8"}},{"cell_type":"code","source":[],"metadata":{"id":"IOYtsPBh0Jrt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**5. Algorithm Selection & Training**"],"metadata":{"id":"fdqgevpS0kh8"}},{"cell_type":"markdown","source":["This is highly dependent on the type of problem that we are solving or the type of result we  are hoping to get at the end of training.\n","You can choose `classifier` algorithm if you are predicting `categories or classes`. And if you are predicting `continuous values`, you cdefinite have to select `regressors`.\n","\n","After selecting the algorithm, you train it using the training dataset. The algorithm learns patterns by adjusting internal parameters to minimize errors.After the training the output of the using your `algorithm` to `train` your` data` is your` model`."],"metadata":{"id":"ybu2TDWu3UET"}},{"cell_type":"code","source":[],"metadata":{"id":"PvbMfSqu0Jo8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**6. Model Evaluation**"],"metadata":{"id":"bTwtxG3y0p0E"}},{"cell_type":"markdown","source":["After training an algorithm, we need to measure how well the ouput(model) performs on unseen data.\n","The model is evaluated using the test data. The classifier and the regressor algorithms have different evaluators.\n","\n","For classifier algorithms, you evaluate their models with:\n","\n","* Accuracy → Percentage of correctly classified samples.\n","* Precision → How many predicted positives are actually correct?\n","* Recall → How many actual positives were correctly predicted?\n","* F1-score → Balances precision and recall.\n","* ROC-AUC → Measures model’s ability to distinguish between classes.\n","\n","For regressor algorithms, you evaluate their models with:\n","\n","\n","* Mean Squared Error (MSE) → Measures average squared differences between predicted and actual values.\n","* Root Mean Squared Error (RMSE) → Square root of MSE, its quite easier to interpret.\n","* R² Score → Measures how well the model explains variance in data (closer to 1 is better)."],"metadata":{"id":"-QlEsdpU5wbL"}},{"cell_type":"code","source":[],"metadata":{"id":"P9-erWOF0Jhl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**7. Model Improvement**"],"metadata":{"id":"18cN-oCp0uoj"}},{"cell_type":"markdown","source":["Not every model do well on unseen data or test data, when that happens, we must look for a way to improve its performance.\n","* One way is to go back to your feature engineering and be sure you have engineered your features as you ought to or you try out regularization for linear models, PCA or Feature Importance to select the best features.\n","\n","* The other way is to optimize the model parameters for better perfomance. Common optimization strategy includes Grid search, Random search and Bayesian optimization.\n","\n","* The process of optimizing an algorithm is called **Hyperparameter Tuning**. ML algorithms have parameters that we must manually tune to get the best performance. For example tree-based algorthms like XGBoost, LGBM and Randomforest."],"metadata":{"id":"11COuq4y7pjS"}},{"cell_type":"code","source":[],"metadata":{"id":"2t1mEkYX0Jer"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**8. Model Deployment**"],"metadata":{"id":"7WQabljW0yUd"}},{"cell_type":"markdown","source":["The process of integrating a trained machine learning model into a real-world application so that users can interact with it is called model deployment.\n","You will save your data model as a `.joblib or .pkl` file.\n","\n","For large numpy arrays, joblie is prefered to pickle files because it handles those arrays more efficiently.\n","\n","For more advanced algorithm models like XGBoost we use `.json or .bin`.\n","For LightGBM we use `.txt`\n","\n","After saving the next thing is to choose your prefered deployment method from the list below(at the time of taking this course there may be other platforms that might be available)\n","\n","* REST API (Flask, FastAPI, Django) – Expose as an API endpoint.\n","* Web App (Streamlit,Dash, Gradio) – Build an interactive UI.\n","* Cloud Deployment (AWS, GCP, Azure) – Scale for production.\n","\n","Then finally,\n","\n","package the app into a container for easy deployment(using docker) and kebernetes to mananage and scale multiple instances.\n","\n","Last 10 cent, Always retrain the model with new data if accuracy drops overtime."],"metadata":{"id":"lDPEySvYAiuj"}},{"cell_type":"code","source":[],"metadata":{"id":"qNrL_ZxWF-En"},"execution_count":null,"outputs":[]}]}